{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tnoX4z8Qvbo0"
      },
      "source": [
        "# Setup Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Iq4WxoDiV1t3"
      },
      "outputs": [],
      "source": [
        "# Install python.\n",
        "!env DEBIAN_FRONTEND=noninteractive apt-get install -y -qq python3 python3-dev python3-venv python3-pip > /dev/null\n",
        "# Upgrade pip\n",
        "!python -m pip install -qq --upgrade pip\n",
        "# Disable TF info logs\n",
        "%env TF_CPP_MIN_LOG_LEVEL=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3dhg7FaKiLdN"
      },
      "outputs": [],
      "source": [
        "!python --version\n",
        "!pip --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jIE59LALvjmE"
      },
      "source": [
        "# Install lm-scorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "colab_type": "code",
        "id": "EPIZ7D2avgmw",
        "outputId": "cd25a3c9-0c42-43a0-d7ca-90258d38d319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: lm-scorer\n",
            "Version: 0.5.0\n",
            "Summary: Language Model based sentences scoring library\n",
            "Home-page: https://github.com/simonepri/lm-scorer#readme\n",
            "Author: Simone Primarosa\n",
            "Author-email: simonepri@outlook.com\n",
            "License: MIT\n",
            "Location: /Users/gregory/TMP/lm-scorer/.venv/lib/python3.9/site-packages\n",
            "Requires: pip, torch, transformers\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip install -qq lm-scorer\n",
        "!pip show lm-scorer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pAWCMVnC9Nqv"
      },
      "source": [
        "# Run the CLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "colab_type": "code",
        "id": "GGEGKmPoTd5U",
        "outputId": "dc429dd4-7bd9-4ce6-dd83-b6b08ad04eaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: lm-scorer [-h] [--model-name MODEL_NAME] [--tokens] [--log-prob]\n",
            "                 [--reduce REDUCE] [--batch-size BATCH_SIZE]\n",
            "                 [--significant-figures SIGNIFICANT_FIGURES] [--cuda CUDA]\n",
            "                 [--debug]\n",
            "                 sentences-file-path\n",
            "\n",
            "Get sentences probability using a language model.\n",
            "\n",
            "positional arguments:\n",
            "  sentences-file-path   A file containing sentences to score, one per line. If\n",
            "                        - is given as filename it reads from stdin instead.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model-name MODEL_NAME, -m MODEL_NAME\n",
            "                        The pretrained language model to use. Can be one of:\n",
            "                        gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2.\n",
            "  --tokens, -t          If provided it provides the probability of each token\n",
            "                        of each sentence.\n",
            "  --log-prob, -lp       If provided log probabilities are returned instead.\n",
            "  --reduce REDUCE, -r REDUCE\n",
            "                        Reduce strategy applied on token probabilities to get\n",
            "                        the sentence score. Available strategies are: prod,\n",
            "                        mean, gmean, hmean.\n",
            "  --batch-size BATCH_SIZE, -b BATCH_SIZE\n",
            "                        Number of sentences to process in parallel.\n",
            "  --significant-figures SIGNIFICANT_FIGURES, -sf SIGNIFICANT_FIGURES\n",
            "                        Number of significant figures to use when printing\n",
            "                        numbers.\n",
            "  --cuda CUDA           If provided it runs the model on the given cuda\n",
            "                        device.\n",
            "  --debug               If provided it provides additional logging in case of\n",
            "                        errors.\n"
          ]
        }
      ],
      "source": [
        "!lm-scorer -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "zHNGxhLbTNVd",
        "outputId": "d31e98f7-3d50-4d73-d842-5d33d97fa00c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing sentences.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile sentences.txt\n",
        "I am going to run a marathon.\n",
        "I am go to run a marathon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "colab_type": "code",
        "id": "ljwsZkjT7QIx",
        "outputId": "8fba073c-009b-40cd-b828-95b1c076d754"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am going to run a marathon.\t-32.551\n",
            "I\t-3.9997\n",
            "Ġam\t-3.0501\n",
            "Ġgoing\t-3.4329\n",
            "Ġto\t-0.075378\n",
            "Ġrun\t-5.6097\n",
            "Ġa\t-1.6184\n",
            "Ġmarathon\t-5.9767\n",
            ".\t-2.3148\n",
            "<|endoftext|>\t-6.4729\n",
            "\n",
            "I am go to run a marathon.\t-42.834\n",
            "I\t-3.9997\n",
            "Ġam\t-3.0501\n",
            "Ġgo\t-10.555\n",
            "Ġto\t-4.5773\n",
            "Ġrun\t-6.7562\n",
            "Ġa\t-1.8721\n",
            "Ġmarathon\t-3.8127\n",
            ".\t-1.9487\n",
            "<|endoftext|>\t-6.2627\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @markdown The LM model to use.\n",
        "MODEL = 'gpt2'  #@param [\"gpt2\", \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\", \"distilgpt2\"]\n",
        "# @markdown Reduction strategy used to compute the sentence score out of tokens' probabilities.\n",
        "REDUCE = 'prod'  #@param [\"prod\", \"mean\", \"gmean\", \"hmean\"]\n",
        "# @markdown CUDA device id to use (e.g. 0), a negative value disables CUDA accelleration.\n",
        "CUDA = -1  #@param {type: \"number\"}\n",
        "# @markdown Number of sentences to simultaneously feed through the model.\n",
        "BATCH_SIZE = 1  #@param {type: \"number\"}\n",
        "\n",
        "!lm-scorer -m $MODEL -r $REDUCE -b $BATCH_SIZE --cuda $CUDA -lp -t sentences.txt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "lm-scorer",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
